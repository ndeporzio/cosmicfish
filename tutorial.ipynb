{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Your Analysis Environment\n",
    "\n",
    "1) Choose a directory to house your project in: \n",
    "```\n",
    ".../<project-directory>\n",
    "```\n",
    "\n",
    "\n",
    "2) Create and activate a fresh Python3 virtual environment there: \n",
    "```\n",
    "$ cd .../<project-directory>\n",
    "$ python -m virtualenv env #Package tested on Python 3.6.8\n",
    "$ source env/bin/activate\n",
    "```\n",
    "\n",
    "3) Download the `cosmicfish` package from Git: \n",
    "```\n",
    "$ git clone git@github.com:ndeporzio/cosmicfish.git\n",
    "```\n",
    "\n",
    "4) Install the `cosmicfish` package. Note that its dependencies will install automatically.\n",
    "```\n",
    "$ cd cosmicfish\n",
    "$ pip install . \n",
    "```\n",
    "\n",
    "5) Launch Jupyter and open `tutorial.ipynb` notebook using Jupyter browser\n",
    "```\n",
    "$ jupyter notebook\n",
    "```\n",
    "\n",
    "6) Create a data folder where the analysis can store spectrum data. This can be anywhere you'd like - you'll specify the path below. \n",
    "```\n",
    "$ mkdir <project-directory>/data\n",
    "```\n",
    "\n",
    "7) Install and build CLASS (if you don't already have a build). Note the `cosmicfish` package includes a method for downloading and installing CLASS for you. \n",
    "```\n",
    "$ python \n",
    ">>> import cosmicfish\n",
    ">>> cosmicfish.install_class('<project-directory>/class')\n",
    ">>> exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Fiducial Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the analysis package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cosmicfish as cf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant python packages... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other setup steps... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Instruct pyplot to use seaborn \n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the paths from the setup of your analysis environment above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Set project, data, CLASS directories \n",
    "projectdir = cf.correct_path(\"~/Desktop/test/\")\n",
    "datastore = cf.correct_path(\"/Volumes/SSD01/data/\")\n",
    "classpath = os.path.join(projectdir, \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the values of your fiducial cosmology and other physical constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Setup fiducial cosmology, note change to N_ncdm... \n",
    "fid = {\"A_s\" : 2.2321e-9, \n",
    "        \"n_s\" : 0.96659,\n",
    "        \"omega_b\" : 0.02226,\n",
    "        \"omega_cdm\" : 0.11271,\n",
    "        \"tau_reio\" : 0.059888,\n",
    "        \"h\" : 0.70148,\n",
    "        \"N_ncdm\" : 1, #Note the change! \n",
    "        \"m_ncdm\" : 0.1, #Comment out for N_ncdm=0\n",
    "        \"T_ncdm\" : 1.4/2.726, #Comment out for N_ncdm=0\n",
    "        \"z_pk\" : 0.7, \n",
    "        \"T_cmb\" : 2.726} #Not necessary, but helps neatness later on\n",
    "\n",
    "A_s = fid['A_s']\n",
    "n_s = fid['n_s']\n",
    "omega_b = fid['omega_b']\n",
    "omega_cdm = fid['omega_cdm']\n",
    "tau_reio = fid['tau_reio']\n",
    "h = fid['h']\n",
    "z_pk = fid['z_pk']\n",
    "T_cmb = fid['T_cmb'] #Units of K\n",
    "\n",
    "c = 2.9979e8 #Units of m/s\n",
    "H = 1000. * 100. * h #Units of m/s/Mpc\n",
    "kp = 0.05 * h #Units of 1/Mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the parameter values you'd like to use to compute the forecast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Setup redshift bins, fiducial relica masses to sample\n",
    "z_table = np.arange(1.0, 1.1, 0.1)\n",
    "m_chi = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the forecast, we want to ensure our cosmological parameters are well converged about the points we are interested in using to calculate Fisher matrices. To do so, we can use the `convergence_analysis` class of `cosmicfish`. \n",
    "\n",
    "We pass to `convergence_analysis` some fiducial cosmology, and then it will vary the parameters of that fiducial cosmology to values specified by the user and compute the corresponding power spectrum derivatives. You can choose to pass specific values of the fiducial cosmology, or choose to vary relative to the fiducial cosmology. \n",
    "\n",
    "First, specify the points in parameter space you'd like to sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T_chi_table = np.arange(1.8, 2.1, 0.02) / T_cmb #Units of T_cmb. We specify absolute values for the T_chi parameter.\n",
    "nonT_relvary = np.arange(1.01, 1.11, 0.01) #We specify values relative to the fiducial cosmology for other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we generate instances of the `convergence_analysis` class. It will search for pre-existing datasets for the specified points in parameter space in the datastore directory - otherwise, it will generate the dataset and place it in datastore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1 = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore); \n",
    "conv2 = cf.convergence_analysis(fid, 'omega_b', 'rel', nonT_relvary, z_table, None, classpath, datastore);\n",
    "conv3 = cf.convergence_analysis(fid, 'omega_cdm', 'rel', nonT_relvary, z_table, None, classpath, datastore);\n",
    "conv4 = cf.convergence_analysis(fid, 'tau_reio', 'rel', nonT_relvary, z_table, None, classpath, datastore);\n",
    "conv5 = cf.convergence_analysis(fid, 'h', 'rel', nonT_relvary, z_table, None, classpath, datastore);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all the useful information generated in the convergence analysis is accessed through the methods of the `convergence_analysis` objects. We use those methods to plot the results of the analysis...\n",
    "\n",
    "### Convergence Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv2.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv3.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv4.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv5.plot_ps(z_index=0, xscale='linear', plotdata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Derivatives of Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1.plot_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Difference of Derivatives of Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_delta_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Other $m_\\chi$\n",
    "\n",
    "We can easily repeate the analysis above for other choice of $m_\\chi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1a = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -1.0), classpath, datastore)\n",
    "conv1b = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.8), classpath, datastore)\n",
    "conv1c = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.6), classpath, datastore)\n",
    "conv1d = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.4), classpath, datastore)\n",
    "conv1e = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.2), classpath, datastore)\n",
    "conv1f = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.0), classpath, datastore)\n",
    "conv1g = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.2), classpath, datastore)\n",
    "conv1h = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.4), classpath, datastore)\n",
    "conv1i = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.6), classpath, datastore)\n",
    "conv1j = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.8), classpath, datastore)\n",
    "conv1k = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 1.0), classpath, datastore)\n",
    "\n",
    "conv1a.plot_dps(z_index=1, xscale='linear')\n",
    "conv1b.plot_dps(z_index=1, xscale='linear')\n",
    "conv1c.plot_dps(z_index=0, xscale='linear')\n",
    "conv1d.plot_dps(z_index=0, xscale='linear')\n",
    "conv1e.plot_dps(z_index=0, xscale='linear')\n",
    "conv1f.plot_dps(z_index=0, xscale='linear')\n",
    "conv1g.plot_dps(z_index=0, xscale='linear')\n",
    "conv1h.plot_dps(z_index=0, xscale='linear')\n",
    "conv1i.plot_dps(z_index=0, xscale='linear')\n",
    "conv1j.plot_dps(z_index=0, xscale='linear')\n",
    "conv1k.plot_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "# Analysis - No Commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import cosmicfish as cf\n",
    "\n",
    "\n",
    "#Instruct pyplot to use seaborn \n",
    "sns.set()\n",
    "\n",
    "#Set project, data, CLASS directories \n",
    "projectdir = cf.correct_path(\"~/Desktop/test/\")\n",
    "datastore = cf.correct_path(\"~/Desktop/test/data/\")\n",
    "classpath = os.path.join(projectdir, \"class\")\n",
    "\n",
    "#Setup fiducial cosmology, note change to N_ncdm... \n",
    "fid = {\"A_s\" : 2.2321e-9, \n",
    "        \"n_s\" : 0.96659,\n",
    "        \"omega_b\" : 0.02226,\n",
    "        \"omega_cdm\" : 0.11271,\n",
    "        \"tau_reio\" : 0.059888,\n",
    "        \"h\" : 0.70148,\n",
    "        \"N_ncdm\" : 1, #Note the change! \n",
    "        \"z_pk\" : 0.7, \n",
    "        \"T_cmb\" : 2.726,\n",
    "        \"T_ncdm\" : 1.5/2.726} #Not necessary, but helps neatness later on\n",
    "\n",
    "A_s = fid['A_s']\n",
    "n_s = fid['n_s']\n",
    "omega_b = fid['omega_b']\n",
    "omega_cdm = fid['omega_cdm']\n",
    "tau_reio = fid['tau_reio']\n",
    "h = fid['h']\n",
    "z_pk = fid['z_pk']\n",
    "T_cmb = fid['T_cmb'] #Units of K\n",
    "\n",
    "c = 2.9979e8 #Units of m/s\n",
    "H = 1000. * 100. * h #Units of m/s/Mpc\n",
    "kp = 0.05 * h #Units of 1/Mpc\n",
    "\n",
    "\n",
    "#Setup redshift bins, fiducial relica masses, relic temps to sample\n",
    "#z_table = np.arange(1.4, 1.5, 0.1)\n",
    "z_table = np.array([1.4, 1.5])\n",
    "m_chi = 1.0\n",
    "#T_chi_table = np.arange(1.0, 2.0, 0.1) / T_cmb #Units of T_cmb\n",
    "T_chi_table = np.array([1.5]) / T_cmb #Units of T_cmb\n",
    "#nonT_relvary = np.arange(1.0, 1.11, 0.01)\n",
    "nonT_relvary = np.array([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 1.0)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.9)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.8)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.7)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.6)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.5)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.4)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.3)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.2)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.1)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., 0.0)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.1)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.2)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.3)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.4)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.5)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.6)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.7)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.8)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -0.9)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datastore = cf.correct_path(\"~/Desktop/test/data/\")\n",
    "conv1 = cf.convergence_analysis(dict(fid, **{'m_ncdm' : np.power(10., -1.0)}), 'n_s', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv1 = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.01, fsky=0.3394)\n",
    "#conv2 = cf.convergence_analysis(fid, 'omega_b', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01);\n",
    "#conv3 = cf.convergence_analysis(fid, 'omega_cdm', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01);\n",
    "#conv4 = cf.convergence_analysis(fid, 'tau_reio', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01);\n",
    "#conv5 = cf.convergence_analysis(fid, 'h', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1.plot_ps(z_index=0, xscale='linear', plotdata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(conv1.spectra[0][0].class_pk[34:60]*np.power(0.70148, -3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv2.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv3.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv4.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv5.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "\n",
    "conv1.plot_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_dps(z_index=0, xscale='linear')\n",
    "\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "\n",
    "conv1.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_delta_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setup redshift bins, fiducial relica masses, relic temps to sample\n",
    "z_table = np.arange(1.0, 1.1, 0.1)\n",
    "m_chi = 0.1\n",
    "T_chi_table = np.arange(1.5, 1.6, 0.1) / T_cmb #Units of T_cmb\n",
    "\n",
    "conv1a = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.01)\n",
    "conv1b = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.02)\n",
    "conv1c = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.03)\n",
    "conv1d = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.04)\n",
    "conv1e = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.05)\n",
    "conv1f = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.06)\n",
    "conv1g = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.07)\n",
    "conv1h = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.08)\n",
    "conv1i = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.09)\n",
    "conv1j = cf.convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_palette(\"Blues_d\", n_colors=10)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "ax1.plot(conv1a.spectra[0][0].k_table, conv1a.dps[0][0], label='step=1%')\n",
    "ax1.plot(conv1b.spectra[0][0].k_table, conv1b.dps[0][0], label='step=2%')\n",
    "ax1.plot(conv1c.spectra[0][0].k_table, conv1c.dps[0][0], label='step=3%')\n",
    "ax1.plot(conv1d.spectra[0][0].k_table, conv1d.dps[0][0], label='step=4%')\n",
    "ax1.plot(conv1e.spectra[0][0].k_table, conv1e.dps[0][0], label='step=5%')\n",
    "ax1.plot(conv1f.spectra[0][0].k_table, conv1f.dps[0][0], label='step=6%')\n",
    "ax1.plot(conv1g.spectra[0][0].k_table, conv1g.dps[0][0], label='step=7%')\n",
    "ax1.plot(conv1h.spectra[0][0].k_table, conv1h.dps[0][0], label='step=8%')\n",
    "ax1.plot(conv1i.spectra[0][0].k_table, conv1i.dps[0][0], label='step=9%')\n",
    "ax1.plot(conv1j.spectra[0][0].k_table, conv1j.dps[0][0], label='step=10%')\n",
    "\n",
    "ax1.set_title(r'$\\partial P_g / \\partial$ T_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax1.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax1.set_ylabel(r'[Mpc$^3$ / (units of T_ncdm)]')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(conv1a.spectra[0][0].k_table, conv1a.dlogps[0][0], label='step=1%')\n",
    "ax2.plot(conv1b.spectra[0][0].k_table, conv1b.dlogps[0][0], label='step=2%')\n",
    "ax2.plot(conv1c.spectra[0][0].k_table, conv1c.dlogps[0][0], label='step=3%')\n",
    "ax2.plot(conv1d.spectra[0][0].k_table, conv1d.dlogps[0][0], label='step=4%')\n",
    "ax2.plot(conv1e.spectra[0][0].k_table, conv1e.dlogps[0][0], label='step=5%')\n",
    "ax2.plot(conv1f.spectra[0][0].k_table, conv1f.dlogps[0][0], label='step=6%')\n",
    "ax2.plot(conv1g.spectra[0][0].k_table, conv1g.dlogps[0][0], label='step=7%')\n",
    "ax2.plot(conv1h.spectra[0][0].k_table, conv1h.dlogps[0][0], label='step=8%')\n",
    "ax2.plot(conv1i.spectra[0][0].k_table, conv1i.dlogps[0][0], label='step=9%')\n",
    "ax2.plot(conv1j.spectra[0][0].k_table, conv1j.dlogps[0][0], label='step=10%')\n",
    "ax2.set_title(r'$\\partial log(P_g) / \\partial$ T_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax2.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax2.set_ylabel(r'[Mpc$^3$ / (units of T_ncdm)]')\n",
    "ax2.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "domega_chi_dT_chi = (3* np.power(1.5, 2.) * 0.1) / (np.power(1.95, 3.) * 94.)\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette(\"Blues_d\", n_colors=10)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "ax1.plot(conv1a.spectra[0][0].k_table, conv1a.dps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax1.plot(conv1b.spectra[0][0].k_table, conv1b.dps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax1.plot(conv1c.spectra[0][0].k_table, conv1c.dps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax1.plot(conv1d.spectra[0][0].k_table, conv1d.dps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax1.plot(conv1e.spectra[0][0].k_table, conv1e.dps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax1.plot(conv1f.spectra[0][0].k_table, conv1f.dps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax1.plot(conv1g.spectra[0][0].k_table, conv1g.dps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax1.plot(conv1h.spectra[0][0].k_table, conv1h.dps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "ax1.plot(conv1i.spectra[0][0].k_table, conv1i.dps[0][0]/domega_chi_dT_chi, label='step=9%')\n",
    "ax1.plot(conv1j.spectra[0][0].k_table, conv1j.dps[0][0]/domega_chi_dT_chi, label='step=10%')\n",
    "\n",
    "ax1.set_title(r'$\\partial P_g / \\partial$ omega_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax1.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax1.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(conv1a.spectra[0][0].k_table, conv1a.dlogps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax2.plot(conv1b.spectra[0][0].k_table, conv1b.dlogps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax2.plot(conv1c.spectra[0][0].k_table, conv1c.dlogps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax2.plot(conv1d.spectra[0][0].k_table, conv1d.dlogps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax2.plot(conv1e.spectra[0][0].k_table, conv1e.dlogps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax2.plot(conv1f.spectra[0][0].k_table, conv1f.dlogps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax2.plot(conv1g.spectra[0][0].k_table, conv1g.dlogps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax2.plot(conv1h.spectra[0][0].k_table, conv1h.dlogps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "ax2.plot(conv1i.spectra[0][0].k_table, conv1i.dlogps[0][0]/domega_chi_dT_chi, label='step=9%')\n",
    "ax2.plot(conv1j.spectra[0][0].k_table, conv1j.dlogps[0][0]/domega_chi_dT_chi, label='step=10%')\n",
    "ax2.set_title(r'$\\partial log(P_g) / \\partial$ omega_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax2.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax2.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax2.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette(\"Blues_d\", n_colors=10)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "ax1.plot(conv1a.spectra[0][0].k_table, conv1a.dps[0][0]/domega_chi_dT_chi - conv1b.dps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax1.plot(conv1b.spectra[0][0].k_table, conv1b.dps[0][0]/domega_chi_dT_chi - conv1c.dps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax1.plot(conv1c.spectra[0][0].k_table, conv1c.dps[0][0]/domega_chi_dT_chi - conv1d.dps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax1.plot(conv1d.spectra[0][0].k_table, conv1d.dps[0][0]/domega_chi_dT_chi - conv1e.dps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax1.plot(conv1e.spectra[0][0].k_table, conv1e.dps[0][0]/domega_chi_dT_chi - conv1f.dps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax1.plot(conv1f.spectra[0][0].k_table, conv1f.dps[0][0]/domega_chi_dT_chi - conv1g.dps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax1.plot(conv1g.spectra[0][0].k_table, conv1g.dps[0][0]/domega_chi_dT_chi - conv1h.dps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax1.plot(conv1h.spectra[0][0].k_table, conv1h.dps[0][0]/domega_chi_dT_chi - conv1i.dps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "\n",
    "ax1.set_title(r'$\\Delta(\\partial P_g / \\partial$ omega_ncdm) for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax1.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax1.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(conv1a.spectra[0][0].k_table, conv1a.dlogps[0][0]/domega_chi_dT_chi - conv1b.dlogps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax2.plot(conv1b.spectra[0][0].k_table, conv1b.dlogps[0][0]/domega_chi_dT_chi - conv1c.dlogps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax2.plot(conv1c.spectra[0][0].k_table, conv1c.dlogps[0][0]/domega_chi_dT_chi - conv1d.dlogps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax2.plot(conv1d.spectra[0][0].k_table, conv1d.dlogps[0][0]/domega_chi_dT_chi - conv1e.dlogps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax2.plot(conv1e.spectra[0][0].k_table, conv1e.dlogps[0][0]/domega_chi_dT_chi - conv1f.dlogps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax2.plot(conv1f.spectra[0][0].k_table, conv1f.dlogps[0][0]/domega_chi_dT_chi - conv1g.dlogps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax2.plot(conv1g.spectra[0][0].k_table, conv1g.dlogps[0][0]/domega_chi_dT_chi - conv1h.dlogps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax2.plot(conv1h.spectra[0][0].k_table, conv1h.dlogps[0][0]/domega_chi_dT_chi - conv1i.dlogps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "ax2.plot(conv1i.spectra[0][0].k_table, conv1i.dlogps[0][0]/domega_chi_dT_chi - conv1j.dlogps[0][0]/domega_chi_dT_chi, label='step=9%')\n",
    "ax2.set_title(r'$\\Delta(\\partial log(P_g) / \\partial$ omega_ncdm) for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax2.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax2.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax2.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import cosmicfish as cf\n",
    "\n",
    "\n",
    "#Instruct pyplot to use seaborn \n",
    "sns.set()\n",
    "\n",
    "#Set project, data, CLASS directories \n",
    "projectdir = cf.correct_path(\"~/Desktop/test/\")\n",
    "datastore = cf.correct_path(\"~/Desktop/test/data/\")\n",
    "classpath = os.path.join(projectdir, \"class\")\n",
    "\n",
    "#Setup fiducial cosmology, note change to N_ncdm... \n",
    "fid = {\"A_s\" : 2.2321e-9, \n",
    "       \"n_s\" : 0.96659,\n",
    "       \"omega_b\" : 0.02226,\n",
    "       \"omega_cdm\" : 0.11271,\n",
    "       \"tau_reio\" : 0.059888,\n",
    "       \"h\" : 0.70148,\n",
    "       \"z_pk\" : 1.4, \n",
    "       \"T_cmb\" : 2.726,\n",
    "       \"N_ncdm\" : 3., \n",
    "       #\"T_ncdm\" : 1.5 / 2.726, #Only uncomment when forecasting relics\n",
    "       \"m_ncdm\" : 0.02} \n",
    "\n",
    "\n",
    "c = 2.9979e8 #Units of m/s\n",
    "H = 1000. * 100. * fid['h'] #Units of m/s/Mpc\n",
    "kp = 0.05 * fid['h'] #Units of 1/Mpc\\\n",
    "skycover = 14000. #Sky coverage of survey in degrees^2\n",
    "\n",
    "\n",
    "#Setup redshift bins, fiducial relica masses, relic temps to sample\n",
    "z_table = np.arange(0.65, 1.85, 0.1)\n",
    "dNdz = np.array([309., 2269., 1923., 2094., 1441., 1353., 1337., 523., 466., 329., 126., 0., 0.])\n",
    "mu_step = 0.05 #For calculating numerical integral wrt mu between -1 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lightrelic = cf.forecast(classpath, datastore, 'neutrino', fid, z_table, dNdz, fcoverage_deg=skycover, dstep=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lightrelic.gen_pg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lightrelic.print_v_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lightrelic.gen_fisher(mu_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lightrelic.print_P_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lssfisher = lightrelic.fisher\n",
    "lssfisher = pd.DataFrame(lssfisher,  columns=['omega_b', 'omega_cdm', 'n_s', 'A_s', 'tau_reio', 'h', 'M_ncdm', 'sigma_fog', 'bLbar', 'alpha_k2'])\n",
    "lssfisher.iloc[:,7] *= 1e3 #To correct units on sigma_fog\n",
    "lssfisher.iloc[7,:] *= 1e3 #To correct units on sigam_fog\n",
    "lssfisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lssfisher.iloc[:,6] *= 3. # Correct from total neutrino mass to single neutrino mass\n",
    "lssfisher.iloc[6,:] *= 3. # Correct from total neutrino mass to single neutrino mass\n",
    "lssfisher = lssfisher.rename(index=str, columns={\"M_ncdm\": \"m_ncdm\"})\n",
    "lssfisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lsscovariance = np.linalg.inv(lssfisher)\n",
    "lsscovariance = pd.DataFrame(lsscovariance, columns=lssfisher.columns)\n",
    "lsscovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmbfisher = pd.read_csv(\"~/Desktop/CMBS4_Fisher.dat\", sep='\\t', header=0)\n",
    "pd.DataFrame(cmbfisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmbfisher.iloc[:,5] *= 100.\n",
    "cmbfisher.iloc[5,:] *= 100.\n",
    "cmbfisher.iloc[:,6] *= 3.\n",
    "cmbfisher.iloc[6,:] *= 3.\n",
    "cmbfisher = cmbfisher.rename(index=str, columns={\"H_0\": \"h\", \"M_ncdm\": \"m_ncdm\"})\n",
    "cmbfisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmbcovariance = pd.DataFrame(np.linalg.inv(cmbfisher), columns=cmbfisher.columns)\n",
    "cmbcovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fullfisher = lssfisher \n",
    "fullfisher.iloc[0:6, 0:6] += cmbfisher\n",
    "fullfisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fullcovariance = pd.DataFrame(np.linalg.inv(fullfisher), columns=fullfisher.columns)\n",
    "fullcovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Fully Marginalized Error on A_s: \", np.sqrt(fullcovariance.iloc[0,0]))\n",
    "print(\"Fully Marginalized Error on n_s: \", np.sqrt(fullcovariance.iloc[1,1]))\n",
    "print(\"Fully Marginalized Error on omega_b: \", np.sqrt(fullcovariance.iloc[2,2]))\n",
    "print(\"Fully Marginalized Error on omega_cdm: \", np.sqrt(fullcovariance.iloc[3,3]))\n",
    "print(\"Fully Marginalized Error on h: \", np.sqrt(fullcovariance.iloc[4,4]))\n",
    "print(\"Fully Marginalized Error on tau_reio: \", np.sqrt(fullcovariance.iloc[5,5]))\n",
    "print(\"Fully Marginalized Error on M_ncdm: \", np.sqrt(fullcovariance.iloc[6,6]))\n",
    "print(\"Fully Marginalized Error on sigma_fog: \", np.sqrt(fullcovariance.iloc[7,7]))\n",
    "print(\"Fully Marginalized Error on bLbar: \", np.sqrt(fullcovariance.iloc[8,8]))\n",
    "print(\"Fully Marginalized Error on alpha_k2: \", np.sqrt(fullcovariance.iloc[9, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(fullcovariance).to_csv(\"~/Desktop/inv_fullfisher.mat\", sep=\"\\t\", index=False, header=['# omega_b', 'omega_cdm', 'n_s', 'A_s', 'tau_reio', 'h', 'm_0', 'sigma_fog', 'bLbar', 'alpha_k2'])\n",
    "#pd.DataFrame(fullcovariance).to_csv(\"~/Desktop/inv_fullfisher.mat\", sep=\"\\t\", index=False, header=['# omega_b', 'omega_cdm', 'n_s', 'A_s', 'tau_reio', 'h', 'm_0', 'sigma_fog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(cmbcovariance).to_csv(\"~/Desktop/inv_cmbfisher.mat\", sep=\"\\t\", index=False, header=['# omega_b', 'omega_cdm', 'n_s', 'A_s', 'tau_reio', 'h', 'm_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(lsscovariance).to_csv(\"~/Desktop/inv_lssfisher.mat\", sep=\"\\t\", index=False, header=['# omega_b', 'omega_cdm', 'n_s', 'A_s', 'tau_reio', 'h', 'm_0', 'sigma_fog', 'bLbar', 'alpha_k2'])\n",
    "#pd.DataFrame(lsscovariance).to_csv(\"~/Desktop/inv_lssfisher.mat\", sep=\"\\t\", index=False, header=['# omega_b', 'omega_cdm', 'n_s', 'A_s', 'tau_reio', 'h', 'm_0', 'sigma_fog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Looking for k = \", 0.2 * fid['h'], \" [Mpc^-1]\")\n",
    "print(lightrelic.k_table)\n",
    "kidx = 69\n",
    "muidx = 20\n",
    "\n",
    "print(lightrelic.k_table[kidx])\n",
    "print(np.arange(-1., 1., mu_step)[muidx])\n",
    "\n",
    "for zidx, zval in enumerate(z_table): \n",
    "    print(\"For z = {0:.2f},\\t P(0.2h, 0) = {1:.2f},\\t nbar * P_(0.2h, 0) = {1:.2e}\".format(zval, \n",
    "                                                                                         lightrelic.Pm[zidx][kidx][muidx],\n",
    "                                                                                         lightrelic.Pm[zidx][kidx][muidx]*lightrelic.n_densities[zidx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#For each z, plot inferred spectrum vs. CLASS data\n",
    "sns.set()\n",
    "sns.set_palette(\"Blues_d\", n_colors=2*len(z_table)+1)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "for zidx, zval in enumerate(z_table[0:1]): \n",
    "    ps = lightrelic.spectra_mid[zidx]\n",
    "    plt.plot(ps.k_table, ps.ps_table, label=(\"z = \" + str(zval)))\n",
    "    plt.plot(ps.class_pk['k (h/Mpc)']*0.70148,\n",
    "             ps.class_pk['P (Mpc/h)^3']*np.power(0.70148, -3),\n",
    "             label='CLASS P(k) Data',\n",
    "             marker='x',\n",
    "             linestyle=':')\n",
    "plt.xlabel(r'k [Mpc$^{-1}$]')\n",
    "plt.ylabel(r'$P_g$ [Mpc$^3$]')\n",
    "plt.xlim(-0.01, 0.2)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#Also plot difference between the two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.nosync",
   "language": "python",
   "name": "env.nosync"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
