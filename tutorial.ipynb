{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Your Analysis Environment\n",
    "\n",
    "1) Choose a directory to house your project in: \n",
    "```\n",
    ".../<project-directory>\n",
    "```\n",
    "\n",
    "\n",
    "2) Create and activate a fresh Python3 virtual environment there: \n",
    "```\n",
    "$ cd .../<project-directory>\n",
    "$ python -m virtualenv env #Package tested on Python 3.6.8\n",
    "$ source env/bin/activate\n",
    "```\n",
    "\n",
    "3) Download the `cosmicfish` package from Git: \n",
    "```\n",
    "$ git clone git@github.com:ndeporzio/cosmicfish.git\n",
    "```\n",
    "\n",
    "4) Install the `cosmicfish` package. Note that its dependencies will install automatically.\n",
    "```\n",
    "$ cd cosmicfish\n",
    "$ pip install . \n",
    "```\n",
    "\n",
    "5) Launch Jupyter and open `tutorial.ipynb` notebook using Jupyter browser\n",
    "```\n",
    "$ jupyter notebook\n",
    "```\n",
    "\n",
    "6) Create a data folder where the analysis can store spectrum data. This can be anywhere you'd like - you'll specify the path below. \n",
    "```\n",
    "$ mkdir <project-directory>/data\n",
    "```\n",
    "\n",
    "7) Install and build CLASS (if you don't already have a build). Note the `cosmicfish` package includes a method for downloading and installing CLASS for you. \n",
    "```\n",
    "$ python \n",
    ">>> import cosmicfish\n",
    ">>> cosmicfish.install_class('<project-directory>/class')\n",
    ">>> exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Fiducial Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the analysis package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cosmicfish as cf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant python packages... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other setup steps... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instruct pyplot to use seaborn \n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the paths from the setup of your analysis environment above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set project, data, CLASS directories \n",
    "projectdir = cf.correct_path(\"~/Desktop/test/\")\n",
    "datastore = cf.correct_path(\"/Volumes/SSD01/data/\")\n",
    "classpath = os.path.join(projectdir, \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the values of your fiducial cosmology and other physical constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup fiducial cosmology, note change to N_ncdm... \n",
    "fid = {\"A_s\" : 2.2321e-9, \n",
    "        \"n_s\" : 0.96659,\n",
    "        \"omega_b\" : 0.02226,\n",
    "        \"omega_cdm\" : 0.11271,\n",
    "        \"tau_reio\" : 0.059888,\n",
    "        \"h\" : 0.70148,\n",
    "        \"N_ncdm\" : 1, #Note the change! \n",
    "        \"m_ncdm\" : 0.1, #Comment out for N_ncdm=0\n",
    "        \"T_ncdm\" : 1.4/2.726, #Comment out for N_ncdm=0\n",
    "        \"z_pk\" : 0.7, \n",
    "        \"T_cmb\" : 2.726} #Not necessary, but helps neatness later on\n",
    "\n",
    "A_s = fid['A_s']\n",
    "n_s = fid['n_s']\n",
    "omega_b = fid['omega_b']\n",
    "omega_cdm = fid['omega_cdm']\n",
    "tau_reio = fid['tau_reio']\n",
    "h = fid['h']\n",
    "z_pk = fid['z_pk']\n",
    "T_cmb = fid['T_cmb'] #Units of K\n",
    "\n",
    "c = 2.9979e8 #Units of m/s\n",
    "H = 1000. * 100. * h #Units of m/s/Mpc\n",
    "kp = 0.05 * h #Units of 1/Mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the parameter values you'd like to use to compute the forecast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup redshift bins, fiducial relica masses to sample\n",
    "z_table = np.arange(1.0, 1.1, 0.1)\n",
    "m_chi = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the forecast, we want to ensure our cosmological parameters are well converged about the points we are interested in using to calculate Fisher matrices. To do so, we can use the `relic_convergence_analysis` class of `cosmicfish`. \n",
    "\n",
    "We pass to `relic_convergence_analysis` some fiducial cosmology, and then it will vary the parameters of that fiducial cosmology to values specified by the user and compute the corresponding power spectrum derivatives. You can choose to pass specific values of the fiducial cosmology, or choose to vary relative to the fiducial cosmology. \n",
    "\n",
    "First, specify the points in parameter space you'd like to sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_chi_table = np.arange(1.8, 2.1, 0.02) / T_cmb #Units of T_cmb. We specify absolute values for the T_chi parameter.\n",
    "nonT_relvary = np.arange(1.01, 1.11, 0.01) #We specify values relative to the fiducial cosmology for other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we generate instances of the `relic_convergence_analysis` class. It will search for pre-existing datasets for the specified points in parameter space in the datastore directory - otherwise, it will generate the dataset and place it in datastore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore); \n",
    "conv2 = cf.relic_convergence_analysis(fid, 'omega_b', 'rel', nonT_relvary, z_table, None, classpath, datastore);\n",
    "conv3 = cf.relic_convergence_analysis(fid, 'omega_cdm', 'rel', nonT_relvary, z_table, None, classpath, datastore);\n",
    "conv4 = cf.relic_convergence_analysis(fid, 'tau_reio', 'rel', nonT_relvary, z_table, None, classpath, datastore);\n",
    "conv5 = cf.relic_convergence_analysis(fid, 'h', 'rel', nonT_relvary, z_table, None, classpath, datastore);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all the useful information generated in the convergence analysis is accessed through the methods of the `relic_convergence_analysis` objects. We use those methods to plot the results of the analysis...\n",
    "\n",
    "### Convergence Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv2.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv3.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv4.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv5.plot_ps(z_index=0, xscale='linear', plotdata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Derivatives of Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.plot_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Difference of Derivatives of Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_delta_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for Other $m_\\chi$\n",
    "\n",
    "We can easily repeate the analysis above for other choice of $m_\\chi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1a = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -1.0), classpath, datastore)\n",
    "conv1b = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.8), classpath, datastore)\n",
    "conv1c = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.6), classpath, datastore)\n",
    "conv1d = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.4), classpath, datastore)\n",
    "conv1e = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., -0.2), classpath, datastore)\n",
    "conv1f = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.0), classpath, datastore)\n",
    "conv1g = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.2), classpath, datastore)\n",
    "conv1h = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.4), classpath, datastore)\n",
    "conv1i = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.6), classpath, datastore)\n",
    "conv1j = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 0.8), classpath, datastore)\n",
    "conv1k = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, np.power(10., 1.0), classpath, datastore)\n",
    "\n",
    "conv1a.plot_dps(z_index=1, xscale='linear')\n",
    "conv1b.plot_dps(z_index=1, xscale='linear')\n",
    "conv1c.plot_dps(z_index=0, xscale='linear')\n",
    "conv1d.plot_dps(z_index=0, xscale='linear')\n",
    "conv1e.plot_dps(z_index=0, xscale='linear')\n",
    "conv1f.plot_dps(z_index=0, xscale='linear')\n",
    "conv1g.plot_dps(z_index=0, xscale='linear')\n",
    "conv1h.plot_dps(z_index=0, xscale='linear')\n",
    "conv1i.plot_dps(z_index=0, xscale='linear')\n",
    "conv1j.plot_dps(z_index=0, xscale='linear')\n",
    "conv1k.plot_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "# Analysis - No Commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import cosmicfish as cf\n",
    "\n",
    "\n",
    "#Instruct pyplot to use seaborn \n",
    "sns.set()\n",
    "\n",
    "#Set project, data, CLASS directories \n",
    "projectdir = cf.correct_path(\"~/Desktop/test/\")\n",
    "datastore = cf.correct_path(\"/Volumes/SSD01/data/\")\n",
    "classpath = os.path.join(projectdir, \"class\")\n",
    "\n",
    "#Setup fiducial cosmology, note change to N_ncdm... \n",
    "fid = {\"A_s\" : 2.2321e-9, \n",
    "        \"n_s\" : 0.96659,\n",
    "        \"omega_b\" : 0.02226,\n",
    "        \"omega_cdm\" : 0.11271,\n",
    "        \"tau_reio\" : 0.059888,\n",
    "        \"h\" : 0.70148,\n",
    "        \"N_ncdm\" : 1, #Note the change! \n",
    "        \"z_pk\" : 0.7, \n",
    "        \"T_cmb\" : 2.726} #Not necessary, but helps neatness later on\n",
    "\n",
    "A_s = fid['A_s']\n",
    "n_s = fid['n_s']\n",
    "omega_b = fid['omega_b']\n",
    "omega_cdm = fid['omega_cdm']\n",
    "tau_reio = fid['tau_reio']\n",
    "h = fid['h']\n",
    "z_pk = fid['z_pk']\n",
    "T_cmb = fid['T_cmb'] #Units of K\n",
    "\n",
    "c = 2.9979e8 #Units of m/s\n",
    "H = 1000. * 100. * h #Units of m/s/Mpc\n",
    "kp = 0.05 * h #Units of 1/Mpc\n",
    "\n",
    "\n",
    "#Setup redshift bins, fiducial relica masses, relic temps to sample\n",
    "#z_table = np.arange(1.4, 1.5, 0.1)\n",
    "z_table = np.array([1.4])\n",
    "m_chi = 1.0\n",
    "#T_chi_table = np.arange(1.0, 2.0, 0.1) / T_cmb #Units of T_cmb\n",
    "T_chi_table = np.array([1.5]) / T_cmb #Units of T_cmb\n",
    "nonT_relvary = np.arange(1.01, 1.11, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv1 = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.01)\n",
    "conv2 = cf.relic_convergence_analysis(fid, 'omega_b', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01);\n",
    "conv3 = cf.relic_convergence_analysis(fid, 'omega_cdm', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01);\n",
    "conv4 = cf.relic_convergence_analysis(fid, 'tau_reio', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01);\n",
    "conv5 = cf.relic_convergence_analysis(fid, 'h', 'rel', nonT_relvary, z_table, None, classpath, datastore, dstep=0.01); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv2.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv3.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv4.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "conv5.plot_ps(z_index=0, xscale='linear', plotdata=True)\n",
    "\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "\n",
    "conv1.plot_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_dps(z_index=0, xscale='linear')\n",
    "\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "print('..................................................................................')\n",
    "\n",
    "conv1.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv2.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv3.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv4.plot_delta_dps(z_index=0, xscale='linear')\n",
    "conv5.plot_delta_dps(z_index=0, xscale='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setup redshift bins, fiducial relica masses, relic temps to sample\n",
    "z_table = np.arange(1.0, 1.1, 0.1)\n",
    "m_chi = 0.1\n",
    "T_chi_table = np.arange(1.5, 1.6, 0.1) / T_cmb #Units of T_cmb\n",
    "\n",
    "conv1a = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.01)\n",
    "conv1b = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.02)\n",
    "conv1c = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.03)\n",
    "conv1d = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.04)\n",
    "conv1e = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.05)\n",
    "conv1f = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.06)\n",
    "conv1g = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.07)\n",
    "conv1h = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.08)\n",
    "conv1i = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.09)\n",
    "conv1j = cf.relic_convergence_analysis(fid, 'T_ncdm', 'abs', T_chi_table, z_table, m_chi, classpath, datastore, dstep=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_palette(\"Blues_d\", n_colors=10)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "ax1.plot(conv1a.spectra[0][0].k_table, conv1a.dps[0][0], label='step=1%')\n",
    "ax1.plot(conv1b.spectra[0][0].k_table, conv1b.dps[0][0], label='step=2%')\n",
    "ax1.plot(conv1c.spectra[0][0].k_table, conv1c.dps[0][0], label='step=3%')\n",
    "ax1.plot(conv1d.spectra[0][0].k_table, conv1d.dps[0][0], label='step=4%')\n",
    "ax1.plot(conv1e.spectra[0][0].k_table, conv1e.dps[0][0], label='step=5%')\n",
    "ax1.plot(conv1f.spectra[0][0].k_table, conv1f.dps[0][0], label='step=6%')\n",
    "ax1.plot(conv1g.spectra[0][0].k_table, conv1g.dps[0][0], label='step=7%')\n",
    "ax1.plot(conv1h.spectra[0][0].k_table, conv1h.dps[0][0], label='step=8%')\n",
    "ax1.plot(conv1i.spectra[0][0].k_table, conv1i.dps[0][0], label='step=9%')\n",
    "ax1.plot(conv1j.spectra[0][0].k_table, conv1j.dps[0][0], label='step=10%')\n",
    "\n",
    "ax1.set_title(r'$\\partial P_g / \\partial$ T_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax1.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax1.set_ylabel(r'[Mpc$^3$ / (units of T_ncdm)]')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(conv1a.spectra[0][0].k_table, conv1a.dlogps[0][0], label='step=1%')\n",
    "ax2.plot(conv1b.spectra[0][0].k_table, conv1b.dlogps[0][0], label='step=2%')\n",
    "ax2.plot(conv1c.spectra[0][0].k_table, conv1c.dlogps[0][0], label='step=3%')\n",
    "ax2.plot(conv1d.spectra[0][0].k_table, conv1d.dlogps[0][0], label='step=4%')\n",
    "ax2.plot(conv1e.spectra[0][0].k_table, conv1e.dlogps[0][0], label='step=5%')\n",
    "ax2.plot(conv1f.spectra[0][0].k_table, conv1f.dlogps[0][0], label='step=6%')\n",
    "ax2.plot(conv1g.spectra[0][0].k_table, conv1g.dlogps[0][0], label='step=7%')\n",
    "ax2.plot(conv1h.spectra[0][0].k_table, conv1h.dlogps[0][0], label='step=8%')\n",
    "ax2.plot(conv1i.spectra[0][0].k_table, conv1i.dlogps[0][0], label='step=9%')\n",
    "ax2.plot(conv1j.spectra[0][0].k_table, conv1j.dlogps[0][0], label='step=10%')\n",
    "ax2.set_title(r'$\\partial log(P_g) / \\partial$ T_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax2.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax2.set_ylabel(r'[Mpc$^3$ / (units of T_ncdm)]')\n",
    "ax2.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "domega_chi_dT_chi = (3* np.power(1.5, 2.) * 0.1) / (np.power(1.95, 3.) * 94.)\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette(\"Blues_d\", n_colors=10)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "ax1.plot(conv1a.spectra[0][0].k_table, conv1a.dps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax1.plot(conv1b.spectra[0][0].k_table, conv1b.dps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax1.plot(conv1c.spectra[0][0].k_table, conv1c.dps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax1.plot(conv1d.spectra[0][0].k_table, conv1d.dps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax1.plot(conv1e.spectra[0][0].k_table, conv1e.dps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax1.plot(conv1f.spectra[0][0].k_table, conv1f.dps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax1.plot(conv1g.spectra[0][0].k_table, conv1g.dps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax1.plot(conv1h.spectra[0][0].k_table, conv1h.dps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "ax1.plot(conv1i.spectra[0][0].k_table, conv1i.dps[0][0]/domega_chi_dT_chi, label='step=9%')\n",
    "ax1.plot(conv1j.spectra[0][0].k_table, conv1j.dps[0][0]/domega_chi_dT_chi, label='step=10%')\n",
    "\n",
    "ax1.set_title(r'$\\partial P_g / \\partial$ omega_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax1.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax1.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(conv1a.spectra[0][0].k_table, conv1a.dlogps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax2.plot(conv1b.spectra[0][0].k_table, conv1b.dlogps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax2.plot(conv1c.spectra[0][0].k_table, conv1c.dlogps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax2.plot(conv1d.spectra[0][0].k_table, conv1d.dlogps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax2.plot(conv1e.spectra[0][0].k_table, conv1e.dlogps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax2.plot(conv1f.spectra[0][0].k_table, conv1f.dlogps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax2.plot(conv1g.spectra[0][0].k_table, conv1g.dlogps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax2.plot(conv1h.spectra[0][0].k_table, conv1h.dlogps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "ax2.plot(conv1i.spectra[0][0].k_table, conv1i.dlogps[0][0]/domega_chi_dT_chi, label='step=9%')\n",
    "ax2.plot(conv1j.spectra[0][0].k_table, conv1j.dlogps[0][0]/domega_chi_dT_chi, label='step=10%')\n",
    "ax2.set_title(r'$\\partial log(P_g) / \\partial$ omega_ncdm for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax2.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax2.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax2.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette(\"Blues_d\", n_colors=10)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "ax1.plot(conv1a.spectra[0][0].k_table, conv1a.dps[0][0]/domega_chi_dT_chi - conv1b.dps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax1.plot(conv1b.spectra[0][0].k_table, conv1b.dps[0][0]/domega_chi_dT_chi - conv1c.dps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax1.plot(conv1c.spectra[0][0].k_table, conv1c.dps[0][0]/domega_chi_dT_chi - conv1d.dps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax1.plot(conv1d.spectra[0][0].k_table, conv1d.dps[0][0]/domega_chi_dT_chi - conv1e.dps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax1.plot(conv1e.spectra[0][0].k_table, conv1e.dps[0][0]/domega_chi_dT_chi - conv1f.dps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax1.plot(conv1f.spectra[0][0].k_table, conv1f.dps[0][0]/domega_chi_dT_chi - conv1g.dps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax1.plot(conv1g.spectra[0][0].k_table, conv1g.dps[0][0]/domega_chi_dT_chi - conv1h.dps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax1.plot(conv1h.spectra[0][0].k_table, conv1h.dps[0][0]/domega_chi_dT_chi - conv1i.dps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "\n",
    "ax1.set_title(r'$\\Delta(\\partial P_g / \\partial$ omega_ncdm) for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax1.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax1.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(conv1a.spectra[0][0].k_table, conv1a.dlogps[0][0]/domega_chi_dT_chi - conv1b.dlogps[0][0]/domega_chi_dT_chi, label='step=1%')\n",
    "ax2.plot(conv1b.spectra[0][0].k_table, conv1b.dlogps[0][0]/domega_chi_dT_chi - conv1c.dlogps[0][0]/domega_chi_dT_chi, label='step=2%')\n",
    "ax2.plot(conv1c.spectra[0][0].k_table, conv1c.dlogps[0][0]/domega_chi_dT_chi - conv1d.dlogps[0][0]/domega_chi_dT_chi, label='step=3%')\n",
    "ax2.plot(conv1d.spectra[0][0].k_table, conv1d.dlogps[0][0]/domega_chi_dT_chi - conv1e.dlogps[0][0]/domega_chi_dT_chi, label='step=4%')\n",
    "ax2.plot(conv1e.spectra[0][0].k_table, conv1e.dlogps[0][0]/domega_chi_dT_chi - conv1f.dlogps[0][0]/domega_chi_dT_chi, label='step=5%')\n",
    "ax2.plot(conv1f.spectra[0][0].k_table, conv1f.dlogps[0][0]/domega_chi_dT_chi - conv1g.dlogps[0][0]/domega_chi_dT_chi, label='step=6%')\n",
    "ax2.plot(conv1g.spectra[0][0].k_table, conv1g.dlogps[0][0]/domega_chi_dT_chi - conv1h.dlogps[0][0]/domega_chi_dT_chi, label='step=7%')\n",
    "ax2.plot(conv1h.spectra[0][0].k_table, conv1h.dlogps[0][0]/domega_chi_dT_chi - conv1i.dlogps[0][0]/domega_chi_dT_chi, label='step=8%')\n",
    "ax2.plot(conv1i.spectra[0][0].k_table, conv1i.dlogps[0][0]/domega_chi_dT_chi - conv1j.dlogps[0][0]/domega_chi_dT_chi, label='step=9%')\n",
    "ax2.set_title(r'$\\Delta(\\partial log(P_g) / \\partial$ omega_ncdm) for z=1.0, m_ncdm=0.1 [eV]')\n",
    "ax2.set_xlabel(r'k [Mpc$^{-1}$]')\n",
    "ax2.set_ylabel(r'[Mpc$^3$ / (units of omega_ncdm)]')\n",
    "ax2.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import cosmicfish as cf\n",
    "\n",
    "\n",
    "#Instruct pyplot to use seaborn \n",
    "sns.set()\n",
    "\n",
    "#Set project, data, CLASS directories \n",
    "projectdir = cf.correct_path(\"~/Desktop/test/\")\n",
    "datastore = cf.correct_path(\"~/Desktop/test/data/\")\n",
    "classpath = os.path.join(projectdir, \"class\")\n",
    "\n",
    "#Setup fiducial cosmology, note change to N_ncdm... \n",
    "fid = {\"A_s\" : 2.2321e-9, \n",
    "       \"n_s\" : 0.96659,\n",
    "       \"omega_b\" : 0.02226,\n",
    "       \"omega_cdm\" : 0.11271,\n",
    "       \"tau_reio\" : 0.059888,\n",
    "       \"h\" : 0.70148,\n",
    "       \"z_pk\" : 1.4, \n",
    "       \"T_cmb\" : 2.726,\n",
    "       \"N_ncdm\" : 1., \n",
    "       \"T_ncdm\" : 1.5 / 2.726, \n",
    "       \"m_ncdm\" : 0.5} \n",
    "\n",
    "\n",
    "c = 2.9979e8 #Units of m/s\n",
    "H = 1000. * 100. * fid['h'] #Units of m/s/Mpc\n",
    "kp = 0.05 * fid['h'] #Units of 1/Mpc\n",
    "\n",
    "\n",
    "#Setup redshift bins, fiducial relica masses, relic temps to sample\n",
    "z_table = np.arange(1.4, 2.0, 0.1)\n",
    "ndensity = [0.63, 0.96, 0.91, 0.84, 0.76, 0.67, 0.60, 0.50, 0.40, 0.29, 0.19, \\\n",
    "0.18, 0.10, 0.06]\n",
    "dstep = 0.03 #Vary each parameter by +-3% to calculate derivatives about fiducial \n",
    "mu_step = 0.05 #For calculating numerical integral wrt mu between -1 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872162.6250710.794513\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872162.99290010.161646\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872163.3723950.413440\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872163.74388720.786116\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872164.124990.025846\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872164.4939430.831994\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872164.86188480.927206\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872165.2320810.520807\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872165.59576490.383763\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872165.95749880.008158\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872166.32282110.393596\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872166.69732710.007084\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872167.0698950.782681\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872167.4410020.829461\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872167.8152990.541393\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872168.17802120.559700\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872168.5475020.139457\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872168.91537210.798231\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872169.2864380.980332\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872169.66187210.837968\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872170.0361160.991617\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872170.4087570.968249\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872170.785530.073533\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872171.15928910.826605\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872171.5437590.902009\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872171.946710.892099\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872172.33267780.999912\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872172.7697920.885908\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872173.172690.004990\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872173.5474110.831759\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872173.9159920.025632\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872174.3081160.773202\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872174.6914340.957680\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872175.0680070.231788\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872175.4394470.740172\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872175.8157370.219516\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872176.2006440.595929\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872176.6703320.812761\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872177.0650940.914579\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872177.4534250.575321\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872177.85082390.155585\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872178.2523470.852608\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872178.63930920.782705\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872179.0911740.549625\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872179.4747550.719583\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872179.8456280.484354\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872180.22864580.133230\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872180.6004680.688126\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872180.96944210.639933\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872181.3462480.694626\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872181.7187470.830440\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872182.0890150.626816\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872182.4657260.322375\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872182.8429460.875748\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872183.2318490.180660\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872183.6277010.449423\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872184.00697180.970940\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872184.4079350.807322\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872184.80892590.930484\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872185.17813520.288526\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872185.547980.062933\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872185.9237460.352938\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872186.30095890.376139\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872186.6863810.977847\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872187.06419780.860106\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872187.4343380.798985\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872187.8215690.773249\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872188.2031160.791169\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872188.5812650.792341\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872188.95765610.328634\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872189.333720.479161\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872189.71319820.184598\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872190.09152410.876011\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872190.4810040.240171\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872190.8674270.631079\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872191.244110.118508\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872191.618540.185071\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872191.99429080.742193\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872192.36915520.012580\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872192.74816510.779377\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872193.1256260.049568\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872193.5042040.492024\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872193.90275720.930546\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872194.28699280.732311\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872194.669430.730155\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872195.04489180.750371\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872195.4394080.510038\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872195.82928590.569910\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872196.2142560.418632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872196.6026380.949132\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872197.02744910.826719\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872197.4224440.634161\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872197.82810120.608743\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872198.2264530.610665\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872198.6223910.035568\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872199.00917980.961858\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872199.3930650.825363\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872199.7866240.051768\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872200.18507220.722139\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872200.59478710.346582\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872200.9837810.282337\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872201.3696960.054293\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872201.7528230.376388\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872202.1416020.087049\n",
      "Dataset already exists at: /Users/nicholasdeporzio/Desktop/test/data/1561872202.5213680.005428\n"
     ]
    }
   ],
   "source": [
    "lightrelic = cf.relic_forecast(fid, z_table, ndensity, dstep, classpath, datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:187: RuntimeWarning: divide by zero encountered in log\n",
      "  for zval in self.z_steps])\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:190: RuntimeWarning: divide by zero encountered in log\n",
      "  for zval in self.z_steps])\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:191: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff = high - low\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:535: RuntimeWarning: divide by zero encountered in log\n",
      "  logP_mu_high = np.log(self.Pg) + np.log(self.RSD) + np.log(self.FOG)\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:540: RuntimeWarning: divide by zero encountered in log\n",
      "  logP_mu_low = np.log(self.Pg) + np.log(self.RSD) + np.log(self.FOG)\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:545: RuntimeWarning: divide by zero encountered in log\n",
      "  logP_mid = np.log(self.Pg) + np.log(self.RSD) + np.log(self.FOG)\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:548: RuntimeWarning: invalid value encountered in subtract\n",
      "  dlogPdmu = (logP_mu_high - logP_mu_low) / (2. * 0.01 * mu)\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:557: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  - logP_mid[zidx][kidx])\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:580: RuntimeWarning: invalid value encountered in add\n",
      "  dlogPdh = dlogPdk * dkdh + dlogPdmu * dmudh\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:577: RuntimeWarning: invalid value encountered in add\n",
      "  dlogPdomega_b = dlogPdk * dkdomega_b + dlogPdmu * dmudomega_b\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:578: RuntimeWarning: invalid value encountered in add\n",
      "  dlogPdomega_cdm = dlogPdk * dkdomega_cdm + dlogPdmu * dmudomega_cdm\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:579: RuntimeWarning: invalid value encountered in add\n",
      "  dlogPdomega_ncdm = dlogPdk * dkdomega_ncdm + dlogPdmu * dmudomega_ncdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher element ( 0 ,  0 ) calculated...\n",
      "Fisher element ( 0 ,  1 ) calculated...\n",
      "Fisher element ( 0 ,  2 ) calculated...\n",
      "Fisher element ( 0 ,  3 ) calculated...\n",
      "Fisher element ( 0 ,  4 ) calculated...\n",
      "Fisher element ( 0 ,  5 ) calculated...\n",
      "Fisher element ( 0 ,  6 ) calculated...\n",
      "Fisher element ( 1 ,  0 ) calculated...\n",
      "Fisher element ( 1 ,  1 ) calculated...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:701: RuntimeWarning: overflow encountered in multiply\n",
      "  * (1. / self.k_table[kidx]))\n",
      "/Users/nicholasdeporzio/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/nicholasdeporzio/Documents/Academic/Research/Projects/cosmicfish/cosmicfish/forecast.py:721: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  * (self.k_table[kidx+1]-self.k_table[kidx]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher element ( 1 ,  2 ) calculated...\n",
      "Fisher element ( 1 ,  3 ) calculated...\n",
      "Fisher element ( 1 ,  4 ) calculated...\n",
      "Fisher element ( 1 ,  5 ) calculated...\n",
      "Fisher element ( 1 ,  6 ) calculated...\n",
      "Fisher element ( 2 ,  0 ) calculated...\n",
      "Fisher element ( 2 ,  1 ) calculated...\n",
      "Fisher element ( 2 ,  2 ) calculated...\n",
      "Fisher element ( 2 ,  3 ) calculated...\n",
      "Fisher element ( 2 ,  4 ) calculated...\n",
      "Fisher element ( 2 ,  5 ) calculated...\n",
      "Fisher element ( 2 ,  6 ) calculated...\n",
      "Fisher element ( 3 ,  0 ) calculated...\n",
      "Fisher element ( 3 ,  1 ) calculated...\n",
      "Fisher element ( 3 ,  2 ) calculated...\n",
      "Fisher element ( 3 ,  3 ) calculated...\n",
      "Fisher element ( 3 ,  4 ) calculated...\n",
      "Fisher element ( 3 ,  5 ) calculated...\n",
      "Fisher element ( 3 ,  6 ) calculated...\n",
      "Fisher element ( 4 ,  0 ) calculated...\n",
      "Fisher element ( 4 ,  1 ) calculated...\n",
      "Fisher element ( 4 ,  2 ) calculated...\n",
      "Fisher element ( 4 ,  3 ) calculated...\n",
      "Fisher element ( 4 ,  4 ) calculated...\n",
      "Fisher element ( 4 ,  5 ) calculated...\n",
      "Fisher element ( 4 ,  6 ) calculated...\n",
      "Fisher element ( 5 ,  0 ) calculated...\n",
      "Fisher element ( 5 ,  1 ) calculated...\n",
      "Fisher element ( 5 ,  2 ) calculated...\n",
      "Fisher element ( 5 ,  3 ) calculated...\n",
      "Fisher element ( 5 ,  4 ) calculated...\n",
      "Fisher element ( 5 ,  5 ) calculated...\n",
      "Fisher element ( 5 ,  6 ) calculated...\n",
      "Fisher element ( 6 ,  0 ) calculated...\n",
      "Fisher element ( 6 ,  1 ) calculated...\n",
      "Fisher element ( 6 ,  2 ) calculated...\n",
      "Fisher element ( 6 ,  3 ) calculated...\n",
      "Fisher element ( 6 ,  4 ) calculated...\n",
      "Fisher element ( 6 ,  5 ) calculated...\n",
      "Fisher element ( 6 ,  6 ) calculated...\n"
     ]
    }
   ],
   "source": [
    "lightrelic.gen_fisher(mu_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.371729e+29</td>\n",
       "      <td>8.567143e+20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>-2.053279e+18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.567143e+20</td>\n",
       "      <td>1.662430e+12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.277530e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>-1.797693e+308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.053279e+18</td>\n",
       "      <td>-3.277530e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.797693e+308</td>\n",
       "      <td>7.849490e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>1.797693e+308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.797693e+308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1              2              3              4  \\\n",
       "0   5.371729e+29  8.567143e+20   0.000000e+00   0.000000e+00  1.797693e+308   \n",
       "1   8.567143e+20  1.662430e+12   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "2   0.000000e+00  0.000000e+00  1.797693e+308  1.797693e+308   0.000000e+00   \n",
       "3   0.000000e+00  0.000000e+00  1.797693e+308  1.797693e+308   0.000000e+00   \n",
       "4  1.797693e+308  0.000000e+00   0.000000e+00   0.000000e+00  1.797693e+308   \n",
       "5  -2.053279e+18 -3.277530e+09   0.000000e+00   0.000000e+00 -1.797693e+308   \n",
       "6   0.000000e+00  0.000000e+00  1.797693e+308  1.797693e+308   0.000000e+00   \n",
       "\n",
       "               5              6  \n",
       "0  -2.053279e+18   0.000000e+00  \n",
       "1  -3.277530e+09   0.000000e+00  \n",
       "2   0.000000e+00  1.797693e+308  \n",
       "3   0.000000e+00  1.797693e+308  \n",
       "4 -1.797693e+308   0.000000e+00  \n",
       "5   7.849490e+06   0.000000e+00  \n",
       "6   0.000000e+00  1.797693e+308  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher = np.nan_to_num(lightrelic.fisher)\n",
    "pd.DataFrame(fisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f5b195891573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfisher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "covariance = np.linalg.inv(fisher)\n",
    "pd.DataFrame(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Marginalized Error on A_s:  6.812131749646603e-13\n",
      "Fully Marginalized Error on n_s:  7.26169420880119e-05\n",
      "Fully Marginalized Error on omega_b:  2.6074297260705823e-06\n",
      "Fully Marginalized Error on oemga_cdm:  5.788754035575009e-06\n",
      "Fully Marginalized Error on h:  nan\n",
      "Fully Marginalized Error on tau_reio:  0.029835813127793067\n",
      "Fully Marginalized Error on omega_ncdm:  1.9771199957609997e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasdeporzio/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Fully Marginalized Error on A_s: \", np.sqrt(covariance[0][0]))\n",
    "print(\"Fully Marginalized Error on n_s: \", np.sqrt(covariance[1][1]))\n",
    "print(\"Fully Marginalized Error on omega_b: \", np.sqrt(covariance[2][2]))\n",
    "print(\"Fully Marginalized Error on oemga_cdm: \", np.sqrt(covariance[3][3]))\n",
    "print(\"Fully Marginalized Error on h: \", np.sqrt(covariance[4][4]))\n",
    "print(\"Fully Marginalized Error on tau_reio: \", np.sqrt(covariance[5][5]))\n",
    "print(\"Fully Marginalized Error on omega_ncdm: \", np.sqrt(covariance[6][6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasdeporzio/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/nicholasdeporzio/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in subtract\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       nan, 0.69314718, 0.69314718, 0.69314718, 0.69314718,\n",
       "       0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log([x for x in range(10)]) - np.log([1 + y/2. for y in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  8],\n",
       "       [18, 32],\n",
       "       [50, 72]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2], [3,4], [5,6]]) * (2 * np.array([[1,2], [3,4], [5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.log([1 + y/2. for y in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.nosync",
   "language": "python",
   "name": "env.nosync"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
